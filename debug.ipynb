{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27afd62f-fb30-4589-a984-67e180f7a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 15 13:18:29 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed3b07f-87a2-40b6-b553-31f1e971aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load python/3.9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c0df13-5c09-4ab4-9a88-d5e78e0e74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring pip: markers 'python_version < \"3\"' don't match your environment\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: dgl in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (1.0.1+computecanada)\n",
      "Requirement already satisfied: pytorch_lightning in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchmetrics in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (0.11.4)\n",
      "Requirement already satisfied: pandas in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (1.5.3+computecanada)\n",
      "Requirement already satisfied: numpy in /home/mootez/.local/lib/python3.9/site-packages (1.24.2+computecanada)\n",
      "Requirement already satisfied: networkx>=2.1 in /home/mootez/.local/lib/python3.9/site-packages (from dgl) (3.0+computecanada)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/mootez/.local/lib/python3.9/site-packages (from dgl) (5.9.4+computecanada)\n",
      "Requirement already satisfied: torch~=1.13.0 in /home/mootez/.local/lib/python3.9/site-packages (from dgl) (1.13.1+computecanada)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/mootez/.local/lib/python3.9/site-packages (from dgl) (2.28.2+computecanada)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/mootez/.local/lib/python3.9/site-packages (from dgl) (1.10.1+computecanada)\n",
      "Requirement already satisfied: tqdm in /home/mootez/.local/lib/python3.9/site-packages (from dgl) (4.64.1+computecanada)\n",
      "Requirement already satisfied: packaging>=17.1 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from pytorch_lightning) (23.0+computecanada)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from pytorch_lightning) (2023.3.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from pytorch_lightning) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from pytorch_lightning) (6.0+computecanada)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/mootez/.local/lib/python3.9/site-packages (from pytorch_lightning) (4.5.0+computecanada)\n",
      "Requirement already satisfied: pytz>=2020.1 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from pandas) (2022.7.1+computecanada)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/mootez/.local/lib/python3.9/site-packages (from pandas) (2.8.1+computecanada)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mootez/.local/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mootez/.local/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (1.26.14+computecanada)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mootez/.local/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (3.4+computecanada)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mootez/.local/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (2022.12.7+computecanada)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\" in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.4+computecanada)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2021a/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1+computecanada)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2+computecanada)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4+computecanada)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3+computecanada)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0+computecanada)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /localscratch/mootez.62589909.0/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2+computecanada)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install dgl pytorch_lightning torchmetrics pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d348f-ddba-497f-a356-cd6bb07c8cae",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe33d2bf-c4d2-4c29-835f-b9d1b7a05f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mootez/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mootez/.local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to /home/mootez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_loader.dataset_ import PlaseDectDataset\n",
    "import pytorch_lightning as pl\n",
    "from utils.data import static_splitter\n",
    "import dgl\n",
    "import multiprocessing\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, args, num_workers = multiprocessing.cpu_count() , batch_size = 32):\n",
    "        super().__init__()\n",
    "        train_split, test_split, val_split =  static_splitter(data_dir)\n",
    "\n",
    "        self.train_split = PlaseDectDataset(train_split, args)\n",
    "        self.test_split = PlaseDectDataset(test_split, args)\n",
    "        self.val_split = PlaseDectDataset(val_split, args)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return dgl.dataloading.GraphDataLoader(\n",
    "        self.train_split,\n",
    "        batch_size=self.batch_size,\n",
    "        num_workers=self.num_workers,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return dgl.dataloading.GraphDataLoader(\n",
    "        self.val_split,\n",
    "        batch_size=self.batch_size,\n",
    "        num_workers=self.num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return dgl.dataloading.GraphDataLoader(\n",
    "        self.test_split,\n",
    "        batch_size=self.batch_size,\n",
    "        num_workers=self.num_workers,\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138cd67-9824-4731-a739-62f03771a490",
   "metadata": {},
   "source": [
    "## Model Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c948b13-390e-4510-8510-4ff421f3a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import Adam\n",
    "import torchmetrics\n",
    "\n",
    "class PlastDectClassifier(pl.LightningModule):\n",
    "    def __init__(self, graph_model, loss_func, lr=1e-3, weight_decay=1e-2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        #### Graph encoder (GGNN, GATv2, GCN)\n",
    "        self.graph_model = graph_model\n",
    "        #### loss function\n",
    "        self.loss_func = loss_func\n",
    "        #### Metrics\n",
    "        self.acc = torchmetrics.Accuracy(task='binary')\n",
    "        self.f1 = torchmetrics.F1Score(task='binary')\n",
    "        self.mcc = torchmetrics.MatthewsCorrCoef(task='binary')\n",
    "        #### Optimizer params\n",
    "        self.lr=lr\n",
    "        self.weight_decay=weight_decay\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.graph_model(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        g, y = batch\n",
    "        logits = self.graph_model(g)\n",
    "        y = y.float().unsqueeze(1)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        preds = preds.float().unsqueeze(1)\n",
    "        acc = self.acc(preds, y)\n",
    "        f1 = self.f1(preds, y)\n",
    "        mcc = self.mcc(preds, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_f1', f1, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_mcc', mcc, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        g, y = batch\n",
    "        logits = self.graph_model(g)\n",
    "        y = y.float().unsqueeze(1)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        preds = preds.float().unsqueeze(1)\n",
    "        acc = self.acc(preds, y)\n",
    "        f1 = self.f1(preds, y)\n",
    "        mcc = self.mcc(preds, y)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('val_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('val_f1', f1, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('val_mcc', mcc, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        g, y = batch\n",
    "        logits = self.graph_model(g)\n",
    "        y = y.float().unsqueeze(1)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        preds = preds.float().unsqueeze(1)\n",
    "        acc = self.acc(preds, y)\n",
    "        f1 = self.f1(preds, y)\n",
    "        mcc = self.mcc(preds, y)\n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('test_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('test_f1', f1, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('test_mcc', mcc, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2408d5-353a-4d7c-bea8-c2cf9f790c5a",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e51a84f-a633-4f03-a45d-b7f851ca68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model import GGNN\n",
    "class args:\n",
    "    dataset=\"java_cc_utc\"\n",
    "    data_src=\"/home/mootez/scratch/code_smells_dataset/ComplexConditional.csv\"\n",
    "    graph_embed_size=256 \n",
    "    feature_size=256 \n",
    "    emb_type=\"w2v\" \n",
    "    w2v=\"/home/mootez/projects/def-tusharma/mootez/pl-agnostic-smell-detection/wv_models/word2vec_ir\"\n",
    "    tok=\"nltk\" \n",
    "    build_method=\"utc\" \n",
    "    window_size=3\n",
    "    read_out=\"sum\"\n",
    "    max_etypes=1\n",
    "    num_steps=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7095927f-f8a9-41d4-9bd7-c2f29b0c225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GGNN(input_dim=args.feature_size, output_dim=args.graph_embed_size,\n",
    "                        num_steps=args.num_steps, max_edge_types=args.max_etypes, read_out=args.read_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fdca160-5b14-4194-91ff-1911135a8a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/15/2023 - 13:32:12] File \"/project/6067998/mootez/BaseGNN/data_loader/dataset_.py\", line 41  \tNumber of val instances: 2000\t\n",
      "[03/15/2023 - 13:32:23] File \"/project/6067998/mootez/BaseGNN/data_loader/dataset_.py\", line 41  \tNumber of train instances: 8000\t\n",
      "[03/15/2023 - 13:32:33] File \"/project/6067998/mootez/BaseGNN/data_loader/dataset_.py\", line 41  \tNumber of eval instances: 145953\t\n"
     ]
    }
   ],
   "source": [
    "data_module = DataModule(args.data_src, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2138fb27-ed10-4001-9efb-fa55bf2fc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5015e0b-5876-4221-b073-b11ffcf40360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/mootez.62589909.0/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'graph_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['graph_model'])`.\n",
      "  rank_zero_warn(\n",
      "/localscratch/mootez.62589909.0/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model = PlastDectClassifier(encoder, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8fe2d07-8ca0-477b-8395-14a3d52a9fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/mootez.62589909.0/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/mootez/.local/lib/python3.9/site-packages/ipyk ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=[0],\n",
    "    max_epochs=3,\n",
    "    log_every_n_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68bf87d5-c26d-4b17-8385-8e8b892d30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e1b5d5a-f224-4c4f-9ceb-55a5d4b6ea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type                   | Params\n",
      "-------------------------------------------------------\n",
      "0 | graph_model | GGNN                   | 460 K \n",
      "1 | loss_func   | BCELoss                | 0     \n",
      "2 | acc         | BinaryAccuracy         | 0     \n",
      "3 | f1          | BinaryF1Score          | 0     \n",
      "4 | mcc         | BinaryMatthewsCorrCoef | 0     \n",
      "-------------------------------------------------------\n",
      "460 K     Trainable params\n",
      "0         Non-trainable params\n",
      "460 K     Total params\n",
      "1.843     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mootez/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]torch.Size([32, 1])\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  1.69it/s]torch.Size([32, 1])\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/mootez.62589909.0/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('val_mcc', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/localscratch/mootez.62589909.0/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (63) is smaller than the logging interval Trainer(log_every_n_steps=100). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/63 [00:00<?, ?it/s] torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/mootez.62589909.0/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('train_mcc', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 1/63 [00:09<10:01,  9.69s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:   3%|▎         | 2/63 [00:09<04:59,  4.91s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:   5%|▍         | 3/63 [00:09<03:17,  3.29s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:   6%|▋         | 4/63 [00:09<02:25,  2.47s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:   8%|▊         | 5/63 [00:09<01:54,  1.98s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  10%|▉         | 6/63 [00:09<01:34,  1.66s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  11%|█         | 7/63 [00:09<01:19,  1.42s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  13%|█▎        | 8/63 [00:09<01:08,  1.25s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  14%|█▍        | 9/63 [00:10<01:00,  1.11s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  16%|█▌        | 10/63 [00:10<00:53,  1.01s/it, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  17%|█▋        | 11/63 [00:10<00:47,  1.09it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  19%|█▉        | 12/63 [00:10<00:42,  1.19it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  21%|██        | 13/63 [00:10<00:38,  1.28it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  22%|██▏       | 14/63 [00:10<00:35,  1.38it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  24%|██▍       | 15/63 [00:10<00:32,  1.47it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  25%|██▌       | 16/63 [00:10<00:30,  1.57it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  27%|██▋       | 17/63 [00:10<00:27,  1.66it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  29%|██▊       | 18/63 [00:10<00:25,  1.75it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  30%|███       | 19/63 [00:15<00:36,  1.22it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  32%|███▏      | 20/63 [00:15<00:33,  1.28it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  33%|███▎      | 21/63 [00:15<00:31,  1.34it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  35%|███▍      | 22/63 [00:15<00:29,  1.40it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  37%|███▋      | 23/63 [00:15<00:27,  1.46it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  38%|███▊      | 24/63 [00:15<00:25,  1.52it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  40%|███▉      | 25/63 [00:15<00:23,  1.58it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  41%|████▏     | 26/63 [00:15<00:22,  1.64it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  43%|████▎     | 27/63 [00:15<00:21,  1.70it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  44%|████▍     | 28/63 [00:15<00:19,  1.76it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  46%|████▌     | 29/63 [00:15<00:18,  1.82it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  48%|████▊     | 30/63 [00:15<00:17,  1.88it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  49%|████▉     | 31/63 [00:15<00:16,  1.94it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  51%|█████     | 32/63 [00:15<00:15,  2.00it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  52%|█████▏    | 33/63 [00:16<00:14,  2.06it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  54%|█████▍    | 34/63 [00:16<00:13,  2.12it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  56%|█████▌    | 35/63 [00:16<00:13,  2.10it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  57%|█████▋    | 36/63 [00:16<00:12,  2.16it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  59%|█████▊    | 37/63 [00:16<00:11,  2.22it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  60%|██████    | 38/63 [00:16<00:11,  2.27it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  62%|██████▏   | 39/63 [00:16<00:10,  2.33it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  63%|██████▎   | 40/63 [00:16<00:09,  2.38it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  65%|██████▌   | 41/63 [00:16<00:09,  2.44it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  67%|██████▋   | 42/63 [00:16<00:08,  2.49it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  68%|██████▊   | 43/63 [00:16<00:07,  2.55it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  70%|██████▉   | 44/63 [00:16<00:07,  2.60it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  71%|███████▏  | 45/63 [00:16<00:06,  2.66it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  73%|███████▎  | 46/63 [00:18<00:06,  2.43it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  75%|███████▍  | 47/63 [00:18<00:06,  2.48it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  76%|███████▌  | 48/63 [00:18<00:05,  2.53it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  78%|███████▊  | 49/63 [00:19<00:05,  2.58it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  79%|███████▉  | 50/63 [00:19<00:04,  2.63it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  81%|████████  | 51/63 [00:19<00:04,  2.68it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  83%|████████▎ | 52/63 [00:19<00:04,  2.72it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  84%|████████▍ | 53/63 [00:19<00:03,  2.77it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  86%|████████▌ | 54/63 [00:19<00:03,  2.82it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  87%|████████▋ | 55/63 [00:19<00:02,  2.87it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  89%|████████▉ | 56/63 [00:19<00:02,  2.92it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  90%|█████████ | 57/63 [00:19<00:02,  2.96it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  92%|█████████▏| 58/63 [00:19<00:01,  3.01it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  94%|█████████▎| 59/63 [00:19<00:01,  3.06it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  95%|█████████▌| 60/63 [00:19<00:00,  3.11it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  97%|█████████▋| 61/63 [00:19<00:00,  3.15it/s, v_num=5]torch.Size([32, 1])\n",
      "Epoch 0:  98%|█████████▊| 62/63 [00:19<00:00,  3.20it/s, v_num=5]torch.Size([16, 1])\n",
      "Epoch 0: 100%|██████████| 63/63 [00:19<00:00,  3.25it/s, v_num=5]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/4562 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/4562 [00:00<?, ?it/s]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 1/4562 [00:00<17:57,  4.23it/s]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 2/4562 [00:08<5:18:36,  4.19s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 3/4562 [00:15<6:35:51,  5.21s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 4/4562 [00:23<7:17:25,  5.76s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 5/4562 [00:30<7:40:53,  6.07s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 6/4562 [00:37<7:55:50,  6.27s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 7/4562 [00:45<8:08:43,  6.44s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 8/4562 [00:52<8:17:27,  6.55s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 9/4562 [00:59<8:23:14,  6.63s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 10/4562 [01:06<8:27:44,  6.69s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 11/4562 [01:14<8:31:22,  6.74s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 12/4562 [01:21<8:37:28,  6.82s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 13/4562 [01:29<8:40:37,  6.87s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 14/4562 [01:36<8:42:32,  6.89s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 15/4562 [01:43<8:44:14,  6.92s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 16/4562 [01:51<8:45:48,  6.94s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 17/4562 [01:58<8:47:40,  6.97s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 18/4562 [02:06<8:50:32,  7.01s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 19/4562 [02:13<8:51:21,  7.02s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 20/4562 [02:20<8:52:08,  7.03s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 21/4562 [02:27<8:53:17,  7.05s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 22/4562 [02:35<8:53:54,  7.06s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 23/4562 [02:42<8:54:22,  7.06s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 24/4562 [02:49<8:55:26,  7.08s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 25/4562 [02:57<8:55:52,  7.09s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 26/4562 [03:04<8:56:37,  7.10s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 27/4562 [03:11<8:56:56,  7.10s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 28/4562 [03:19<8:57:11,  7.11s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 29/4562 [03:26<8:58:18,  7.13s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 30/4562 [03:34<8:59:15,  7.14s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 31/4562 [03:41<8:59:22,  7.14s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 32/4562 [03:48<8:59:29,  7.15s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 33/4562 [03:55<8:59:37,  7.15s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 34/4562 [04:03<8:59:46,  7.15s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 35/4562 [04:11<9:01:49,  7.18s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 36/4562 [04:18<9:01:51,  7.18s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 37/4562 [04:25<9:01:56,  7.19s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "torch.Size([32, 1])                                                7.19s/it]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 39/4562 [04:42<9:05:28,  7.24s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 40/4562 [04:50<9:06:42,  7.25s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 41/4562 [04:57<9:06:38,  7.25s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 42/4562 [05:04<9:06:35,  7.26s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 43/4562 [05:12<9:07:00,  7.26s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 44/4562 [05:19<9:06:53,  7.26s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 45/4562 [05:26<9:06:46,  7.26s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 46/4562 [05:34<9:07:08,  7.27s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 47/4562 [05:41<9:07:04,  7.27s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 48/4562 [05:49<9:07:24,  7.28s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 49/4562 [05:56<9:07:16,  7.28s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 50/4562 [06:03<9:07:08,  7.28s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 51/4562 [06:11<9:07:56,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 52/4562 [06:19<9:07:51,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 53/4562 [06:26<9:08:04,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 54/4562 [06:33<9:07:55,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 55/4562 [06:41<9:07:46,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 56/4562 [06:48<9:08:01,  7.30s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|          | 57/4562 [06:55<9:07:53,  7.30s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|▏         | 58/4562 [07:03<9:07:55,  7.30s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|▏         | 59/4562 [07:10<9:07:30,  7.30s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|▏         | 60/4562 [07:17<9:07:06,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|▏         | 61/4562 [07:24<9:06:59,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|▏         | 62/4562 [07:32<9:06:52,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|▏         | 63/4562 [07:39<9:06:29,  7.29s/it]\u001b[Atorch.Size([32, 1])\n",
      "\n",
      "Validation DataLoader 0:   1%|▏         | 64/4562 [07:46<9:06:07,  7.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/mootez.62589909.0/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e1833-16dd-40f8-9617-f230093da05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
